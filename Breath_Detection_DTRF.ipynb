{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Breath_Detection_DTRF.ipynb",
      "provenance": [],
      "mount_file_id": "1xM8vmhitRdbNkayjxcUwCrI38tjnIyWO",
      "authorship_tag": "ABX9TyNsZC7UUKdu7+heI2YNiCej",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JayKarhade/Breath-Classification/blob/main/Breath_Detection_DTRF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohReDLf2SClp"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
        "from sklearn import preprocessing\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "import matplotlib.pylab as plt\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3E2bwkjOSLBJ",
        "outputId": "e1586efc-cbce-418a-8180-2c064a7f2f81"
      },
      "source": [
        "df1 = pd.read_csv('/content/drive/MyDrive/breath_detect/dataset.csv')\n",
        "df2 = pd.read_csv('/content/drive/MyDrive/breath_detect/class_labels.csv')\n",
        "x = df1.to_numpy()[:,1:390]*100000\n",
        "y = df2.to_numpy()[:,1]\n",
        "print(x.shape,y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(455, 389) (455,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bGUUYWzSN0F"
      },
      "source": [
        "#Shuffle data\n",
        "indices = list(range(x.shape[0]))\n",
        "np.random.shuffle(indices)\n",
        "x = x[indices]\n",
        "y=y[indices]\n",
        "#x = x.reshape(x.shape[0],x.shape[1],1)\n",
        "\n",
        "##Train-Test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "#y= to_categorical(y)\n",
        "x_train_raw, x_test_raw, y_train_raw, y_test_raw = train_test_split(x,y, test_size=0.25, random_state=1)\n",
        "x_train_raw, x_val_raw, y_train_raw, y_val_raw = train_test_split(x_train_raw,y_train_raw, test_size=2/8, random_state=1)\n",
        "\n",
        "label_names = ['Normal', 'Slow', 'Fast', 'Deep']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNB-UTunSTY3"
      },
      "source": [
        "import scipy.stats as st\n",
        "from scipy.fftpack import fft, fftfreq \n",
        "from scipy.signal import argrelextrema\n",
        "import operator\n",
        "\n",
        "def stat_area_features(x, Te=1.0):\n",
        "\n",
        "    mean_ts = np.mean(x, axis=1).reshape(-1,1) # mean\n",
        "    max_ts = np.amax(x, axis=1).reshape(-1,1) # max\n",
        "    min_ts = np.amin(x, axis=1).reshape(-1,1) # min\n",
        "    std_ts = np.std(x, axis=1).reshape(-1,1) # std\n",
        "    skew_ts = st.skew(x, axis=1).reshape(-1,1) # skew\n",
        "    kurtosis_ts = st.kurtosis(x, axis=1).reshape(-1,1) # kurtosis \n",
        "    iqr_ts = st.iqr(x, axis=1).reshape(-1,1) # interquartile rante\n",
        "    mad_ts = np.median(np.sort(abs(x - np.median(x, axis=1).reshape(-1,1)),\n",
        "                               axis=1), axis=1).reshape(-1,1) # median absolute deviation\n",
        "    area_ts = np.trapz(x, axis=1, dx=Te).reshape(-1,1) # area under curve\n",
        "    sq_area_ts = np.trapz(x ** 2, axis=1, dx=Te).reshape(-1,1) # area under curve ** 2\n",
        "\n",
        "    return np.concatenate((mean_ts,max_ts,min_ts,std_ts,skew_ts,kurtosis_ts,\n",
        "                           iqr_ts,mad_ts,area_ts,sq_area_ts), axis=1)\n",
        "\n",
        "def frequency_domain_features(x, Te=1.0):\n",
        "\n",
        "    # As the DFT coefficients and their corresponding frequencies are symetrical arrays\n",
        "    # with respect to the middle of the array we need to know if the number of readings \n",
        "    # in x is even or odd to then split the arrays...\n",
        "    if x.shape[1]%2 == 0:\n",
        "        N = int(x.shape[1]/2)\n",
        "    else:\n",
        "        N = int(x.shape[1]/2) - 1\n",
        "    xf = np.repeat(fftfreq(x.shape[1],d=Te)[:N].reshape(1,-1), x.shape[0], axis=0) # frequencies\n",
        "    dft = np.abs(fft(x, axis=1))[:,:N] # DFT coefficients   \n",
        "    \n",
        "    # statistical and area features\n",
        "    dft_features = stat_area_features(dft, Te=1.0)\n",
        "    # weighted mean frequency\n",
        "    dft_weighted_mean_f = np.average(xf, axis=1, weights=dft).reshape(-1,1)\n",
        "    # 5 first DFT coefficients \n",
        "    dft_first_coef = dft[:,:5]    \n",
        "    # 5 first local maxima of DFT coefficients and their corresponding frequencies\n",
        "    dft_max_coef = np.zeros((x.shape[0],5))\n",
        "    dft_max_coef_f = np.zeros((x.shape[0],5))\n",
        "    for row in range(x.shape[0]):\n",
        "        # finds all local maximas indexes\n",
        "        extrema_ind = argrelextrema(dft[row,:], np.greater, axis=0) \n",
        "        # makes a list of tuples (DFT_i, f_i) of all the local maxima\n",
        "        # and keeps the 5 biggest...\n",
        "        extrema_row = sorted([(dft[row,:][j],xf[row,j]) for j in extrema_ind[0]],\n",
        "                             key=operator.itemgetter(0), reverse=True)[:5] \n",
        "        for i, ext in enumerate(extrema_row):\n",
        "            dft_max_coef[row,i] = ext[0]\n",
        "            dft_max_coef_f[row,i] = ext[1]    \n",
        "    \n",
        "    return np.concatenate((dft_features,dft_weighted_mean_f,dft_first_coef,\n",
        "                           dft_max_coef,dft_max_coef_f), axis=1)\n",
        "\n",
        "def make_feature_vector(x, Te=1.0):\n",
        "\n",
        "    # Raw signals :  stat and area features\n",
        "    features_xt = stat_area_features(x, Te=Te)\n",
        "    \n",
        "    # Jerk signals :  stat and area features\n",
        "    features_xt_jerk = stat_area_features((x[:,1:]-x[:,:-1])/Te, Te=Te)\n",
        "    \n",
        "    # Raw signals : frequency domain features \n",
        "    features_xf = frequency_domain_features(x, Te=1/Te)\n",
        "    \n",
        "    # Jerk signals : frequency domain features \n",
        "    features_xf_jerk = frequency_domain_features((x[:,1:]-x[:,:-1])/Te, Te=1/Te)\n",
        "        \n",
        "    return np.concatenate((features_xt, features_xt_jerk, features_xf,features_xf_jerk), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZLYZT64TYTm",
        "outputId": "be68089b-febf-4dac-d39f-3a9ebfd6af80"
      },
      "source": [
        "X_train = make_feature_vector(x_train_raw, Te=1/50)\n",
        "X_test = make_feature_vector(x_test_raw, Te=1/50)\n",
        "\n",
        "print(\"X_train shape : {}\".format(X_train.shape))\n",
        "print(\"X_test shape: {}\".format(X_test.shape))\n",
        "\n",
        "scaler = preprocessing.StandardScaler().fit(X_train)\n",
        "X_train = scaler.transform(X_train) \n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape : (255, 72)\n",
            "X_test shape: (114, 72)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xz42FfACThc4",
        "outputId": "b8cc377d-bbd7-428d-c5ee-4cd7d0e63af5"
      },
      "source": [
        "clf = tree.DecisionTreeClassifier()\n",
        "clf = clf.fit(X_train, y_train_raw)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(classification_report(y_test_raw, y_pred, target_names=label_names))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.64      0.74      0.68        19\n",
            "        Slow       0.95      0.73      0.83        26\n",
            "        Fast       0.86      0.82      0.84        44\n",
            "        Deep       0.83      1.00      0.91        25\n",
            "\n",
            "    accuracy                           0.82       114\n",
            "   macro avg       0.82      0.82      0.81       114\n",
            "weighted avg       0.84      0.82      0.82       114\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8PpJPcaU_b2",
        "outputId": "514263f4-a9ea-49a9-a0e3-05bd3fae0b0c"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf_rf = RandomForestClassifier(max_depth=20, random_state=0)\n",
        "clf_rf = clf_rf.fit(x_train_raw,y_train_raw)\n",
        "y_pred = clf_rf.predict(x_test_raw)\n",
        "print(classification_report(y_test_raw, y_pred, target_names=label_names))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.57      0.42      0.48        19\n",
            "        Slow       0.68      0.81      0.74        26\n",
            "        Fast       0.80      0.75      0.78        44\n",
            "        Deep       0.64      0.72      0.68        25\n",
            "\n",
            "    accuracy                           0.70       114\n",
            "   macro avg       0.67      0.67      0.67       114\n",
            "weighted avg       0.70      0.70      0.70       114\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kD-cO_h0W3vp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}