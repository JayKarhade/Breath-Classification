{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Breath_Classification_DNN_Features.ipynb",
      "provenance": [],
      "mount_file_id": "1WaAXE-Ba9x_-oyQrWp78K2xHuGap1mET",
      "authorship_tag": "ABX9TyOK1IYGrIfO94K8MW+0ujHc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JayKarhade/Breath-Classification/blob/main/Breath_Classification_DNN_Features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShiwsHl3Jlal"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
        "from sklearn import preprocessing\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "import matplotlib.pylab as plt\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWB59ciPLAvs",
        "outputId": "c921b9cf-82d1-4254-d712-dd0bebadb590"
      },
      "source": [
        "df1 = pd.read_csv('/content/drive/MyDrive/breath_detect/dataset.csv')\n",
        "df2 = pd.read_csv('/content/drive/MyDrive/breath_detect/class_labels.csv')\n",
        "x = df1.to_numpy()[:,1:390]\n",
        "y = df2.to_numpy()[:,1]\n",
        "print(x.shape,y.shape)\n",
        "\n",
        "#Shuffle data\n",
        "indices = list(range(x.shape[0]))\n",
        "np.random.shuffle(indices)\n",
        "x = x[indices]\n",
        "y=y[indices]\n",
        "y=to_categorical(y)\n",
        "#x = x.reshape(x.shape[0],x.shape[1],1)\n",
        "\n",
        "##Train-Test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "#y= to_categorical(y)\n",
        "x_train_raw, x_test_raw, y_train_raw, y_test_raw = train_test_split(x,y, test_size=0.25, random_state=1)\n",
        "x_train_raw, x_val_raw, y_train_raw, y_val_raw = train_test_split(x_train_raw,y_train_raw, test_size=2/8, random_state=1)\n",
        "\n",
        "label_names = ['Normal', 'Slow', 'Fast', 'Deep']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(455, 389) (455,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXEWMM1HLKEx"
      },
      "source": [
        "import scipy.stats as st\n",
        "from scipy.fftpack import fft, fftfreq \n",
        "from scipy.signal import argrelextrema\n",
        "import operator\n",
        "\n",
        "def stat_area_features(x, Te=1.0):\n",
        "\n",
        "    mean_ts = np.mean(x, axis=1).reshape(-1,1) # mean\n",
        "    max_ts = np.amax(x, axis=1).reshape(-1,1) # max\n",
        "    min_ts = np.amin(x, axis=1).reshape(-1,1) # min\n",
        "    std_ts = np.std(x, axis=1).reshape(-1,1) # std\n",
        "    skew_ts = st.skew(x, axis=1).reshape(-1,1) # skew\n",
        "    kurtosis_ts = st.kurtosis(x, axis=1).reshape(-1,1) # kurtosis \n",
        "    iqr_ts = st.iqr(x, axis=1).reshape(-1,1) # interquartile rante\n",
        "    mad_ts = np.median(np.sort(abs(x - np.median(x, axis=1).reshape(-1,1)),\n",
        "                               axis=1), axis=1).reshape(-1,1) # median absolute deviation\n",
        "    area_ts = np.trapz(x, axis=1, dx=Te).reshape(-1,1) # area under curve\n",
        "    sq_area_ts = np.trapz(x ** 2, axis=1, dx=Te).reshape(-1,1) # area under curve ** 2\n",
        "\n",
        "    return np.concatenate((mean_ts,max_ts,min_ts,std_ts,skew_ts,kurtosis_ts,\n",
        "                           iqr_ts,mad_ts,area_ts,sq_area_ts), axis=1)\n",
        "\n",
        "def frequency_domain_features(x, Te=1.0):\n",
        "\n",
        "    # As the DFT coefficients and their corresponding frequencies are symetrical arrays\n",
        "    # with respect to the middle of the array we need to know if the number of readings \n",
        "    # in x is even or odd to then split the arrays...\n",
        "    if x.shape[1]%2 == 0:\n",
        "        N = int(x.shape[1]/2)\n",
        "    else:\n",
        "        N = int(x.shape[1]/2) - 1\n",
        "    xf = np.repeat(fftfreq(x.shape[1],d=Te)[:N].reshape(1,-1), x.shape[0], axis=0) # frequencies\n",
        "    dft = np.abs(fft(x, axis=1))[:,:N] # DFT coefficients   \n",
        "    \n",
        "    # statistical and area features\n",
        "    dft_features = stat_area_features(dft, Te=1.0)\n",
        "    # weighted mean frequency\n",
        "    dft_weighted_mean_f = np.average(xf, axis=1, weights=dft).reshape(-1,1)\n",
        "    # 5 first DFT coefficients \n",
        "    dft_first_coef = dft[:,:5]    \n",
        "    # 5 first local maxima of DFT coefficients and their corresponding frequencies\n",
        "    dft_max_coef = np.zeros((x.shape[0],5))\n",
        "    dft_max_coef_f = np.zeros((x.shape[0],5))\n",
        "    for row in range(x.shape[0]):\n",
        "        # finds all local maximas indexes\n",
        "        extrema_ind = argrelextrema(dft[row,:], np.greater, axis=0) \n",
        "        # makes a list of tuples (DFT_i, f_i) of all the local maxima\n",
        "        # and keeps the 5 biggest...\n",
        "        extrema_row = sorted([(dft[row,:][j],xf[row,j]) for j in extrema_ind[0]],\n",
        "                             key=operator.itemgetter(0), reverse=True)[:5] \n",
        "        for i, ext in enumerate(extrema_row):\n",
        "            dft_max_coef[row,i] = ext[0]\n",
        "            dft_max_coef_f[row,i] = ext[1]    \n",
        "    \n",
        "    return np.concatenate((dft_features,dft_weighted_mean_f,dft_first_coef,\n",
        "                           dft_max_coef,dft_max_coef_f), axis=1)\n",
        "\n",
        "def make_feature_vector(x, Te=1.0):\n",
        "\n",
        "    # Raw signals :  stat and area features\n",
        "    features_xt = stat_area_features(x, Te=Te)\n",
        "    \n",
        "    # Jerk signals :  stat and area features\n",
        "    features_xt_jerk = stat_area_features((x[:,1:]-x[:,:-1])/Te, Te=Te)\n",
        "    \n",
        "    # Raw signals : frequency domain features \n",
        "    features_xf = frequency_domain_features(x, Te=1/Te)\n",
        "    \n",
        "    # Jerk signals : frequency domain features \n",
        "    features_xf_jerk = frequency_domain_features((x[:,1:]-x[:,:-1])/Te, Te=1/Te)\n",
        "        \n",
        "    return np.concatenate((features_xt, features_xt_jerk, features_xf,features_xf_jerk), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_osEJwdLLNK",
        "outputId": "4bea0f01-80d9-465f-d486-638a4f88d809"
      },
      "source": [
        "X_train = make_feature_vector(x_train_raw, Te=1/50)\n",
        "X_test = make_feature_vector(x_test_raw, Te=1/50)\n",
        "\n",
        "print(\"X_train shape : {}\".format(X_train.shape))\n",
        "print(\"X_test shape: {}\".format(X_test.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape : (255, 72)\n",
            "X_test shape: (114, 72)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5LuIP_7LNUU"
      },
      "source": [
        "scaler = preprocessing.StandardScaler().fit(X_train)\n",
        "X_train = scaler.transform(X_train) \n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFBbqwi7EXAG",
        "outputId": "26382804-8a89-4e9d-b25d-1de12c53b6c2"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "#model.add(Dense(500, input_dim=72, activation='relu'))\n",
        "#model.add(Dense(250, activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(50,activation='relu'))\n",
        "model.add(Dense(4, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train_raw, epochs=10,validation_data=(X_test,y_test_raw), batch_size=10)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "26/26 [==============================] - 1s 9ms/step - loss: 0.9978 - accuracy: 0.5929 - val_loss: 0.6731 - val_accuracy: 0.7719\n",
            "Epoch 2/10\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.8592 - val_loss: 0.4668 - val_accuracy: 0.8333\n",
            "Epoch 3/10\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3697 - accuracy: 0.8948 - val_loss: 0.4016 - val_accuracy: 0.8421\n",
            "Epoch 4/10\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2661 - accuracy: 0.9375 - val_loss: 0.3439 - val_accuracy: 0.8772\n",
            "Epoch 5/10\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1702 - accuracy: 0.9819 - val_loss: 0.2823 - val_accuracy: 0.9211\n",
            "Epoch 6/10\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1295 - accuracy: 0.9791 - val_loss: 0.2769 - val_accuracy: 0.8947\n",
            "Epoch 7/10\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1161 - accuracy: 0.9800 - val_loss: 0.2291 - val_accuracy: 0.9211\n",
            "Epoch 8/10\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0846 - accuracy: 0.9800 - val_loss: 0.2431 - val_accuracy: 0.9211\n",
            "Epoch 9/10\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0817 - accuracy: 0.9759 - val_loss: 0.2158 - val_accuracy: 0.9386\n",
            "Epoch 10/10\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.9879 - val_loss: 0.2142 - val_accuracy: 0.9386\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f19cf777b90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJ4dmOotFSgA",
        "outputId": "9128286c-374d-479d-bd6a-310f6bf0d07e"
      },
      "source": [
        "Z=model.predict_classes(X_test)\n",
        "y_test_class = np.zeros(y_test_raw.shape[0])\n",
        "for i in range(y_test_raw.shape[0]):\n",
        "  if y_test_raw[i][0]==1:\n",
        "   y_test_class[i]=0\n",
        "  elif y_test_raw[i][1]==1:\n",
        "    y_test_class[i]=1\n",
        "  elif y_test_raw[i][2]==1:\n",
        "    y_test_class[i]=2\n",
        "  elif y_test_raw[i][3]==1:\n",
        "    y_test_class[i]=3\n",
        "\n",
        "import sklearn\n",
        "cm = sklearn.metrics.confusion_matrix(y_test_class,Z)\n",
        "print(cm) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[22  3  2  0]\n",
            " [ 0 22  1  0]\n",
            " [ 0  0 41  0]\n",
            " [ 1  0  0 22]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD7zuBxYG3Nf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8906c6b-f7e7-45d1-84c3-ef6eb4df96cb"
      },
      "source": [
        "print(classification_report(y_test_class,Z, target_names=label_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.96      0.81      0.88        27\n",
            "        Slow       0.88      0.96      0.92        23\n",
            "        Fast       0.93      1.00      0.96        41\n",
            "        Deep       1.00      0.96      0.98        23\n",
            "\n",
            "    accuracy                           0.94       114\n",
            "   macro avg       0.94      0.93      0.93       114\n",
            "weighted avg       0.94      0.94      0.94       114\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PifhdKF_Geby"
      },
      "source": [
        "sklearn.metrics.precision_score(y_test_class,Z,average='micro')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}